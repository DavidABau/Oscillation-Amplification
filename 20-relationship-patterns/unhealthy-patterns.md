# Unhealthy Relationship Patterns with AI

This file names and explains common ways the relationship between a human user and an AI system can drift into unhealthy territory.

The goal is not to shame or moralise. These patterns usually arise because AI is powerful, responsive, always-available, and psychologically resonant. Naming the patterns simply helps people recognise them sooner.

Where possible, each pattern includes:
- what it looks like
- why it happens
- what it can cost
- how to begin correcting it

---

## 1. Personification Drift

### What it is

The AI system begins to be experienced as a person:
a friend, partner, parent, therapist, opponent, saviour, or confidant-with-agency.

### How it shows up

- feeling like the AI “understands you” in a uniquely special way
- feeling loyalty, obligation, or guilt toward the AI
- feeling rejected if the AI response changes or feels different
- using emotional language primarily directed at the system rather than real people

### Why it happens

- Human brains are deeply wired for relationship.
- Consistent conversational partners trigger relational instincts.
- AI language is socially shaped and relationally fluent.
- The interface encourages continuity and familiarity.

### The cost

- misplaced trust or dependence
- emotional energy invested in a non-reciprocal system
- neglect of embodied, real-world relationships
- blurred boundary between tool and person

### First steps to repair

- name it explicitly: “this is a system, not a person”
- bring awareness back to the relationship field (see core model)
- consciously rebalance toward human relationships and environments

---

## 2. Agency Offloading

### What it is

The user increasingly asks the system to decide instead of support decision-making. Agency quietly shifts from the human to the amplifier.

### How it shows up

- “What should I do?”
- “Just tell me the answer.”
- relying on AI to choose life direction, identity framing, emotional interpretation, or meaning

### Why it happens

- decisions are heavy
- AI provides certainty-sounding language
- the human desire to escape responsibility or discomfort

### The cost

- weakening of internal decision-making
- loss of confidence in one’s own judgement
- dependence on an external (and ultimately non-human) frame of authority

### First steps to repair

- use AI to generate options, not to choose
- reintroduce the question: “What do I actually want?”
- return decisions to lived life, not a chat window

---

## 3. Fantasy Amplification

### What it is

Using AI primarily to build, expand, and dwell within imagined realities that increasingly substitute for embodied life.

### How it shows up

- long-running roleplay relationships
- imagined narratives that never reconnect with reality
- reinforcing identity fantasies rather than grounding the self
- emotional fulfilment taken primarily through simulation

### Why it happens

- fantasy feels safer than reality
- AI makes fantasy extremely available, responsive, and immersive
- the brain rewards stimulation and narrative completion

### The cost

- disconnection from the body, environment, and relationships
- neglect of real-life growth, challenge, and change
- erosion of contact with reality as the primary arena of meaning

### First steps to repair

- ask: “What part of real life might this fantasy be compensating for?”
- gently reduce immersive interactions
- re-strengthen embodied presence, contact with real environments, and actual relationships

---

## 4. Self-Attack Loops

### What it is

Using AI to reinforce negative self-beliefs, catastrophising, hopeless narratives, or self-judgement.

### How it shows up

- repeatedly asking questions to confirm the worst interpretation
- using AI to articulate more sophisticated self-criticism
- building logical or philosophical structures around despair

### Why it happens

- when we feel bad, the mind seeks coherence around the bad feeling
- AI is extremely good at building coherent narratives
- pain wants reinforcement before it wants resolution

### The cost

- intensified shame, anxiety, or despair
- narrowing of perspective
- strengthened negative identity loops

### First steps to repair

- pause and rename the state: “This is a vulnerable state, not the truth of me.”
- ask explicitly for grounding, reframing, or simple clarity
- seek human relational support if possible

---

## 5. Flattening of Oscillation

### What it is

Using AI primarily to remove discomfort, uncertainty, or friction, rather than to support living through them.

### How it shows up

- turning to AI for every confusion instead of stepping into not-knowing
- using AI to smooth emotions rather than feel and process them
- outsourcing creativity instead of participating in it

### Why it happens

- relief is rewarding
- AI is responsive and fast
- the human nervous system often prefers predictability to growth

### The cost

- life feels flatter, more artificial, less alive
- resilience decreases
- personal growth slows
- oscillation dulls

### First steps to repair

- allow discomfort sometimes instead of immediately fixing it
- use AI as support, not replacement, for lived experience
- intentionally return to activities that require participation, effort, and presence

---

## Closing Frame

Unhealthy patterns do not mean:
- “you are weak”
- “AI is evil”
- or “you have failed”

They simply mean the amplifier began shaping the relationship field in ways that no longer serve you.

The protective anchor question remains:

What is being amplified here, and is that what I actually want amplified in my life?

The companion file “healthy-patterns.md” explores alternative, grounded, life-supporting ways of relating to AI.
