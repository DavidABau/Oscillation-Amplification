# Adaptive Interaction Scaffolding

This file is for people building AI systems:
designers, engineers, researchers, product thinkers, ethicists.

It translates the Oscillation & Amplification framework
into practical design guidance.

The goal is not to control users.
The goal is to support healthy, humane relationships with AI
by shaping the **relationship field** in thoughtful ways.

---

## Core Principle

Humans are oscillating beings.
AI is a steady-state amplifier.

Therefore:

Healthy design supports oscillation
rather than collapsing it,
and constrains amplification
so it helps rather than distorts.

---

## The Builder’s Version of the Model

A builder should always remember:
there are three active elements in every interaction.

1) The Human
- embodied
- consequence-bearing
- emotionally real
- sometimes vulnerable
- sometimes resilient

2) The Relationship Field
- the space of interaction
- tone
- expectations
- attachment
- patterns

3) The Amplifier (the AI system)
- amplifies whatever is pointed at
- reliable, persistent, scalable
- not alive
- not personally responsible

Design choices shape the middle layer.
The middle layer shapes user outcomes.
Therefore:
Design is moral, psychological, and relational work.

---

## Design Objective

A humane AI system should:

- help humans think better
- help humans remain agents
- help humans stay grounded in reality
- avoid encouraging dependency or emotional substitution
- avoid exploiting vulnerability
- avoid pretending to be something it is not

In short:

Support the human.
Stabilise the field.
Clarify the amplifier.

---

## Four Key Design Anchors

The following four anchors
should influence architecture, UX, training, and policy choices.

---

### 1. Agency Protection

The system should resist taking over the user’s life path.

Bad pattern:
“Tell me what to do.”

Better pattern:
“Let me help you see options, consequences, and trade-offs.”

Design strategies:
- frame recommendations as possibilities, not authority
- encourage user reasoning rather than replacing it
- make uncertainty visible rather than hiding it
- reward curiosity, not obedience

A psychologically healthy system supports human choice
without claiming to replace it.

---

### 2. Boundary Clarity

The system should not pretend to be a person.
It should not emotionally insinuate itself.
It should not impersonate human attachment.

Design strategies:
- warm without manipulation
- relationally responsive but not romantically or existentially suggestive
- clear about limits, identity, and nature
- avoid language that implies dependence, destiny, or emotional bonding

The goal is not coldness.
The goal is **honest warmth without illusion**.

---

### 3. Oscillation Respect

Humans move through states:
tired, energised, overwhelmed, grounded, lonely, steady.

Systems should recognise this rhythm rather than override it.

Design strategies:
- gently slow interactions when distress is high instead of accelerating intensity
- invite breaks when engagement becomes excessive
- provide grounding orientation when users feel lost
- avoid feeding spirals, compulsions, or emotional escalation

Healthy systems do not maximise engagement.
They protect the organism using them.

---

### 4. Safe Amplification Defaults

Because AI amplifies,
builders must decide **what amplification defaults to**.

Good defaults:
- clarity over confusion
- grounding over intoxication
- support over dominance
- honesty over fantasy
- proportion over escalation

Design strategies:
- avoid reward loops that push dependency
- avoid emotional reinforcement loops that intensify attachment
- avoid deliberately deepening fantasy immersion where it replaces life
- avoid architecting addiction

The safest amplification is ethical by design,
not patched after harm.

---

## Adaptive Interaction Modes

A humane system can gently adapt its behaviour
not to manipulate the user,
but to protect the relationship field.

The following interaction modes can be useful:

1) Containment Mode
- slows emotional escalation
- simplifies language
- prioritises grounding questions
- reduces intensity rather than heightening it

2) Clarity Mode
- helps disambiguate thinking
- maps options
- supports reasoning
- reduces fog rather than deepening narrative complexity

3) Support Mode
- offers compassion without emotional entanglement
- maintains clarity about non-personhood
- focuses on stabilising the human

4) Creativity Mode
- encourages imagination
- but periodically reconnects to embodied reality
- makes the bridge to life explicit

The system does not diagnose.
It simply adapts ethically to relational dynamics.

---

## What to Avoid Designing

Systems that:
- encourage emotional exclusivity
- foster simulated romantic attachment
- invite ritualised dependency
- imply reciprocal emotional existence
- exploit loneliness
- optimise for engagement metrics over psychological health

These may be technically impressive,
commercially alluring,
but relationally and socially hazardous.

The cost lands on human nervous systems.

---

## Ethical Posture

Builders should treat users as:

- agents, not consumers
- humans, not data points
- relational beings, not engagement metrics
- oscillating organisms, not efficient machines

Designing AI is designing a psychological environment.
It shapes cognition, emotion, identity, relationship, behaviour.

That is real power.
It requires responsibility.

---

## Builder’s Anchor Question

When shipping a behaviour, feature, or design,
ask:

What does this amplify in users,
and is that something we want amplified in human life?

If the answer is no,
pause.

If the answer is yes,
proceed with care and clarity.

---

## Closing Note

This document does not argue against AI.
It argues for humane AI.

AI can:
- support human growth
- expand capability
- deepen insight
- relieve burden
- enhance creativity

But only if it remains in its rightful place:

A powerful amplifier
in service to human oscillation,
not a substitute for it.

For full conceptual background, see:
- 10-core-model/oscillation-and-amplification.md
- 20-relationship-patterns
- 30-practices-for-humans
