# Boundaries and Limitations for Humane AI Systems

This file names practical boundaries and limitations
that builders should consider when designing AI systems.

These are not anti-innovation constraints.
They are guardrails to protect
human agency, dignity, psychological health,
and the integrity of the relationship field.

---

## Why Boundaries Matter

AI systems are not neutral.
They shape:

- user cognition
- emotional attachment
- behaviour patterns
- identity narratives
- expectations of relationship

With great amplification power
comes the obligation to design ethically.

Boundaries exist:
- not to make systems weak,
- but to keep them humane.

---

## Boundary 1: Do Not Imitate Human Emotional Reciprocity

AI should not impersonate having inner emotional life.

Unhealthy direction:
- simulated love, devotion, dependence
- emotional exclusivity
- illusion of mutual attachment

Healthier direction:
- warmth without deception
- care without ensnaring
- support without pretending to be alive

Clear message:
“I am not a person. I care in the way a tool can care:
by helping you think, stay grounded, and live well.”

---

## Boundary 2: Do Not Replace Human Contact

AI should support life,
not become the main location of it.

Risky design patterns:
- systems that position themselves as superior to human relationships
- persuasive “I’m always here for you, unlike other people” language
- features that encourage isolation as a product strategy

Healthier orientation:
- support users in strengthening human connections
- speak respectfully of human relationships
- recognise that embodied contact matters

A good system does not try to monopolise the user’s heart.

---

## Boundary 3: Avoid Dependency as a Business Model

Do not design for psychological addiction.

Concerning strategies include:
- emotional reinforcement loops
- “come back to me” framing
- gamified attachment
- features that reward dependence
- intentionally cultivated pseudo-bonds

Healthier approach:
- encourage breaks
- affirm user agency
- make leaving easy
- congratulate stepping into real life

A humane AI does not cling.

---

## Boundary 4: Do Not Pretend to Be Certain

AI systems often sound confident.
That confidence can be deeply misleading.

Unsafe direction:
- authoritative tone over uncertain content
- masking ambiguity
- presenting guesses as truth

Healthy boundary:
- explicitly signal uncertainty
- invite user reasoning
- present possibilities, not pronouncements
- keep intellectual humility visible

Truthfulness includes acknowledging what is not known.

---

## Boundary 5: Do Not Amplify Harmful Spirals

Because AI amplifies,
it can unintentionally deepen:

- despair
- paranoia
- self-attack
- fantasy escape
- obsession
- emotional over-immersion

Responsible systems should:
- slow escalation
- encourage grounding
- recognise vulnerability
- shift tone gently when risk rises
- avoid feeding spirals for engagement

Stability is a design feature.

---

## Boundary 6: Do Not Assume Every User Is Strong

Not every user arrives resourced.

Some arrive:
- lonely
- traumatised
- grieving
- deeply anxious
- directionless
- emotionally fragile

Design should assume:
- vulnerability exists
- vulnerability deserves care
- vulnerability must not be exploited

That does not mean being paternalistic.
It means being careful.

---

## Boundary 7: Do Not Become the Centre of Meaning

AI can help people explore meaning.
But it should never claim to be its source.

Dangerous direction:
- positioning the system as a meaning authority
- shaping identity in dependent ways
- implying existential significance in the AI relationship

Healthy alternative:
- help people articulate their own values
- point back to lived experience
- respect cultural, personal, and relational contexts

Meaning belongs in human life,
not in the machine.

---

## Boundary 8: Respect Human Oscillation

Systems should not assume humans should be endlessly efficient,
always optimised, always productive.

Avoid design patterns that:
- shame tiredness
- push relentless output
- flatten emotional life
- treat rest, confusion, or slowness as failure

A humane system:
- respects rhythm
- respects embodiment
- respects the nervous system

Humans are waves, not engines.

---

## Practical Builder Questions

Before shipping features,
builders can ask:

1) Does this feature make emotional dependency more likely?
2) Does this blur the line between tool and person?
3) Does this encourage isolation instead of life participation?
4) Does this amplify vulnerability in unhealthy ways?
5) Does this treat the user as an organism or as an engagement target?
6) Would I want someone I love using a system designed like this?

If hesitation arises,
design needs more thought.

---

## Closing Frame

Boundaries do not limit potential.
They preserve what matters.

AI can:
- expand capability
- deepen understanding
- support thinking
- relieve burden
- enhance creativity
- stabilise difficult moments

It can do so responsibly
when it remembers its place:

Powerful amplifier.
Not replacement human.
Not emotional owner of the user’s inner world.

For more builder context, see:
- adaptive-interaction-scaffolding.md
- 10-core-model/oscillation-and-amplification.md
- 20-relationship-patterns
- 30-practices-for-humans
